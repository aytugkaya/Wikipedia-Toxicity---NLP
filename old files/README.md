Abstract

Wikipedia, the largest and most popular general reference work on the World Wide Web, is based on open collaboration.

Open collaboration has its own difficulties since it enables insertion of contents that are toxic, due to identity hate, improper language or obscenetiy.

A model, utilizing Recursive Neural Networks (RNN), that’s capable of detecting different types of of toxicity like threats, obscenity, insults, and identity-based hate will be built and used to block improper comments.

Dataset files are to big to be loaded. Please download at:
https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data

Inıtial phase has been completed with baseline ML models. RNN section pending completion.
